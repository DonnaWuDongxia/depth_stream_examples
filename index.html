
<!DOCTYPE html>
<html lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>three.js - Depth Video</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0">
        <style>
            body {
                font-family: Monospace;
                background-color: #000000;
                margin: 0px;
                overflow: hidden;
            }

            #info {
                color: #ffffff;

                font-family: Monospace;
                font-size: 13px;
                text-align: center;
                font-weight: bold;

                position: absolute;
                top: 0px; width: 100%;
                padding: 5px;
            }

            a {
                color: #0040ff;
            }

            #buttons {
                position: absolute;
                right: 0px;
                bottom: 0px;
            }
        </style>
    </head>
    <body>
        <script src="libs/three.min.js"></script>
        <script src='libs/dat.gui.min.js'></script>
        <script src="libs/Detector.js"></script>
        <script src="libs/stats.min.js"></script>

        <script id="vs" type="x-shader/x-vertex">

            uniform sampler2D map;

            uniform float width;
            uniform float height;
            uniform float nearClipping, farClipping;

            uniform float pointSize;
            uniform float zOffset;

            uniform float depthEncoding;

            varying vec2 vUv;

            const float XtoZ = 1.11146; // tan( 1.0144686 / 2.0 ) * 2.0;
            const float YtoZ = 0.83359; // tan( 0.7898090 / 2.0 ) * 2.0;

            const float max = 3000.;
            const float min = 150.;
            const float np = 512.;
            const float w = max;

            // Implement the depth decode scheme proposed in paper
            // "Adapting Standard Video Codecs for Depth Streaming"
            highp float decodeAdaptiveDepth(highp vec4 rgba) {
                highp float L = rgba.b;
                highp float Ha = rgba.g;
                highp float Hb = rgba.r;
                highp float p = np / w;

                highp float m = mod(floor( 4. * L / p - 0.5 ), 4.);
                highp float q;
                if (m == 0.) {
                    q = p / 2. * Ha;
                } else if (m == 1.) {
                    q = p / 2. * Hb;
                } else if (m == 2.) {
                    q = p / 2. * (1. - Ha);
                } else if (m == 3.) {
                    q = p / 2. * (1. - Hb);
                }

                highp float l = L - (mod(L - p / 8., p)) + p / 4. * m - p / 8.;

                highp float d = w * (l + q);
                if (d < min)
                    return 1.0;
                else
                    return (l + q);
            }

            // Implement the BIT2 scheme described in paper
            // "Adapting Standard Video Codecs for Depth Streaming"
            highp float decodeRawDepth(highp vec4 rgba) {
                highp float d = 255. * rgba.b * 256. +
                                255. * rgba.g * 4. + 
                                255. * rgba.r / 8.;
                if (d < min || d > w)
                    return 1.0;
                else
                    return d / w;
            }

            // Implement the equation (5) in paper
            // "3-D Video Representation Using Depth Maps"
            highp float decodeGrayscaleDepth(highp vec4 rgba) {
                highp float d = 1.0 / (rgba.b * (1.0 / min - 1.0 / max) + 1.0 / max);
                return d / max;
            }

            void main() {

                vUv = vec2( position.x / width, position.y / height );

                vec4 color = texture2D( map, vUv );

                float depth = 1.0;

                if (depthEncoding == 0.)
                    depth = decodeGrayscaleDepth(color);
                else if (depthEncoding == 1.)
                    depth = decodeAdaptiveDepth(color);
                else if (depthEncoding == 2.)
                    depth = decodeRawDepth(color);

                // Projection code by @kcmic
                float z = depth * (farClipping - nearClipping) + nearClipping;

                vec4 pos = vec4(
                    ( position.x / width - 0.5 ) * z * XtoZ,
                    ( position.y / height - 0.5 ) * z * YtoZ,
                    - z + zOffset,
                    1.0);

                gl_PointSize = pointSize;
                gl_Position = projectionMatrix * modelViewMatrix * pos;

            }

        </script>

        <script id="fs" type="x-shader/x-fragment">

            uniform sampler2D map;
            uniform sampler2D rgbMap;
            uniform float enableRgbTexture;

            varying vec2 vUv;

            void main() {

                if (enableRgbTexture == 1.) {
                    vec4 color = texture2D( rgbMap, vUv );
                    gl_FragColor = vec4( color.r, color.g, color.b, smoothstep( 8000.0, -8000.0, gl_FragCoord.z / gl_FragCoord.w ) );
                } else {
                    gl_FragColor = vec4( 0.5, 0.5, 0.5, smoothstep( 8000.0, -8000.0, gl_FragCoord.z / gl_FragCoord.w ) );
                }
            }

        </script>

        <script>

            var container;
            var info;

            var scene, camera, light, renderer;
            var geometry, cube, mesh, material;
            var mouse, center;
            var stats;
            var intervalId, animationId;

            var live = false;
            var button = document.getElementById("depth_capture_button");

            var depthVideo, depthTexture, depthCanvas, depthContext;
            var rgbVideo, rgbTexture, rgbCanvas, rgbContext;

            var gui;

            var showDepthVideo = true;
            var depthStream = null;

            var enableRgbTexture = false;
            var rgbStream = null;

            var kLiveDepthStream = "Depth Stream from Live Capture";
            var kReplayDepthStream = "Depth Stream from depth_video.webm";

            if ( Detector.webgl ) {

                navigator.webkitGetUserMedia({
                    audio: false,
                    video: { "mandatory": { "depth": "depth"}},
                },
                function(stream) {
                    depthStream = stream;
                    navigator.webkitGetUserMedia({
                        audio: false,
                        video: { "mandatory": { "depth": "rgbd"}},
                        },
                        function(stream) {
                            rgbStream = stream;
                            init(window.URL.createObjectURL(depthStream),
                                 window.URL.createObjectURL(rgbStream), 
                                 kLiveDepthStream);
                        },
                        function(e) {
                        console.log('fails to obtain rgbd stream ' + e);
                    });
                },
                function(e) {
                    console.log('fails to obtain depth stream ' + e);
                });

            } else {

                document.body.appendChild( Detector.getWebGLErrorMessage() );

            }

            function reset() {
                depthVideo.pause();
                rgbVideo.pause();
                if (depthStream) {
                    depthStream = null;
                }
                if (rgbStream) {
                    rgbStream = null;
                }
                clearInterval(intervalId);
                cancelAnimationFrame(animationId);
                document.body.removeChild(container);
                document.body.removeChild(info);
                document.body.removeChild(depthVideo);
                document.body.removeChild(rgbVideo);
                document.body.removeChild(gui.domElement);
            }

            function drawVideo() {
                if ( depthVideo.readyState === depthVideo.HAVE_ENOUGH_DATA ) {
                    depthContext.drawImage(depthVideo, 0, 0, depthCanvas.width, depthCanvas.height);
                    depthTexture.needsUpdate = true;
                }

                if ( enableRgbTexture && rgbVideo && rgbVideo.readyState === rgbVideo.HAVE_ENOUGH_DATA ) {
                    rgbContext.drawImage(rgbVideo, 0, 0, rgbCanvas.width, rgbCanvas.height);
                    rgbTexture.needsUpdate = true;
                }
            }


            function init(depthStream, rgbStream, description) {
                container = document.createElement( 'div' );
                document.body.appendChild( container );

                info = document.createElement( 'div' );
                info.id = 'info';
                info.innerHTML = description;
                document.body.appendChild( info );

                stats = new Stats();
                stats.domElement.style.position = 'absolute';
                stats.domElement.style.bottom = '0px';
                stats.domElement.style.left = '0px';
                container.appendChild( stats.domElement );

                camera = new THREE.PerspectiveCamera( 50, window.innerWidth / window.innerHeight, 1, 10000 );
                camera.position.set( 0, 0, 500 );

                scene = new THREE.Scene();
                center = new THREE.Vector3();
                center.z = - 1000;


                depthVideo = document.createElement( 'video' );
                depthCanvas = document.createElement( 'canvas');
                depthCanvas.width = 320;
                depthCanvas.height = 240;
                depthContext = depthCanvas.getContext('2d');

                rgbVideo = document.createElement( 'video' );
                rgbCanvas = document.createElement( 'canvas');
                rgbCanvas.width = 320;
                rgbCanvas.height = 240;
                rgbContext = rgbCanvas.getContext('2d');

                function VideoReady () {
                    depthTexture = new THREE.Texture( depthCanvas );
                    rgbTexture = new THREE.Texture( rgbCanvas );

                    var width = 320, height = 240;
                    var nearClipping = 150, farClipping = 3000;

                    geometry = new THREE.Geometry();

                    for ( var i = 0, l = width * height; i < l; i ++ ) {

                        var vertex = new THREE.Vector3();
                        vertex.x = ( i % width );
                        vertex.y = Math.floor( i / width );

                        geometry.vertices.push( vertex );

                    }

                    material = new THREE.ShaderMaterial( {

                        uniforms: {

                            "map": { type: "t", value: depthTexture },
                            "rgbMap": { type: "t", value: rgbTexture },
                            "width": { type: "f", value: width },
                            "height": { type: "f", value: height },
                            "nearClipping": { type: "f", value: nearClipping },
                            "farClipping": { type: "f", value: farClipping },
                            "pointSize": { type: "f", value: 2 },
                            "zOffset": { type: "f", value: 0 },
                            "depthEncoding": { type: "f", value: 0},
                            "enableRgbTexture": { type: "f", value: 0}

                        },
                        vertexShader: document.getElementById( 'vs' ).textContent,
                        fragmentShader: document.getElementById( 'fs' ).textContent,
                        depthTest: false, depthWrite: false,
                        transparent: true

                    });

                    mesh = new THREE.ParticleSystem( geometry, material );
                    mesh.position.x = 0;
                    mesh.position.y = 0;
                    scene.add( mesh );

                    gui = new dat.GUI({autoPlace: false});
                    document.body.appendChild(gui.domElement);
                    gui.domElement.style.position = "absolute";
                    gui.domElement.style.top = "0px";
                    gui.domElement.style.right = "5px";
                    gui.add( material.uniforms.nearClipping, 'value', 1, 10000, 1.0 ).name( 'nearClipping' );
                    gui.add( material.uniforms.farClipping, 'value', 1, 10000, 1.0 ).name( 'farClipping' );
                    gui.add( material.uniforms.pointSize, 'value', 1, 10, 1.0 ).name( 'pointSize' );
                    gui.add( material.uniforms.zOffset, 'value', 0, 4000, 1.0 ).name( 'zOffset' );
                    gui.add( window, 'showDepthVideo' ).name('Show Depth Video').onChange(function(value) {
                        if (value)
                            video.style.display = 'block';
                        else
                            video.style.display = 'none';
                    });
                    gui.add( window, 'enableRgbTexture').name('Enable RGB Texture').onChange(function(value) {
                        if (value) {
                            material.uniforms.enableRgbTexture.value = 1.0;
                        } else {
                            material.uniforms.enableRgbTexture.value = 0.0;
                        }
                    });
                    gui.add( material.uniforms.depthEncoding, 'value', { Grayscale: 0, Adaptive: 1, Raw: 2 } ).name('Depth Encoding');
                    gui.close();

                    intervalId = setInterval(drawVideo, 1000 / 30 );
                    animate();

                }

                var isDepthVideoReady = false;
                var isRgbVideoReady = false;

                depthVideo.addEventListener( 'loadedmetadata', function(event) {
                    isDepthVideoReady = true;

                    if (isRgbVideoReady)
                        VideoReady();
                });
                rgbVideo.addEventListener( 'loadedmetadata', function(event) {
                    isRgbVideoReady = true;

                    if (isDepthVideoReady)
                        VideoReady();
                });

                depthVideo.src = depthStream;
                depthVideo.loop = true;
                depthVideo.play();

                depthVideo.style.position = 'absolute';
                depthVideo.style.top = '0px';
                depthVideo.style.left = '0px';
                document.body.appendChild(depthVideo);

                rgbVideo.src = rgbStream;
                rgbVideo.loop = true;
                rgbVideo.play();

                rgbVideo.style.position = 'absolute';
                rgbVideo.style.top = '240px';
                rgbVideo.style.left = '0px';
                document.body.appendChild(rgbVideo);

                renderer = new THREE.WebGLRenderer();
                renderer.setSize( window.innerWidth, window.innerHeight );
                container.appendChild( renderer.domElement );

                mouse = new THREE.Vector3( 0, 0, 1 );

                document.addEventListener( 'mousemove', onDocumentMouseMove, false );

                //

                window.addEventListener( 'resize', onWindowResize, false );
            }

            function onWindowResize() {

                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();

                renderer.setSize( window.innerWidth, window.innerHeight );

            }

            function onDocumentMouseMove( event ) {

                mouse.x = ( event.clientX - window.innerWidth / 2 ) * 8;
                mouse.y = ( event.clientY - window.innerHeight / 2 ) * 8;

            }

            function animate() {

                animationId = requestAnimationFrame( animate );

                render();
                stats.update();

            }

            function render() {

                camera.position.x += ( mouse.x - camera.position.x ) * 0.05;
                camera.position.y += ( - mouse.y - camera.position.y ) * 0.05;
                camera.lookAt( center );

                renderer.render( scene, camera );

            }

        </script>
    </body>
</html>
